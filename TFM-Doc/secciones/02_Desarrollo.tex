\chapter{Methodology}

% 1. Classification process

% 2. Datasets

% 2. Correlation of components with original features
%   - Show plots (Slope Chart)
%   - 

% 3. Spearman Rank correlation between techniques


\section{Datasets}
This section introduces the datasets utilized in this master's thesis. The aim is to provide a comprehensive overview of the datasets, including their sources, characteristics, and any preprocessing steps applied.

\subsection{Artificial Dataset}


\subsection{Our Database of Faces (ORL) Dataset}
This dataset was created at the AT\&T Laboratories in Cambridge, UK, in the context of a face recognition project the laboratory was doing with the Speech, Vision and Robotics Group of the Cambridge University Engineering Department. It contains face images taken between April 1992 and April 1994, 10 images of 40 different subjects, a total of 400 images. It consists of grayscale images of 40 individuals, with 10 images per person. The dataset was collected under controlled conditions, with variations in facial expression, lighting conditions, and facial details.

Each image in the ORL dataset has a resolution of 92 pixels by 112 pixels. The images were captured under different poses, including variations in head rotation and tilt, providing a diverse set of facial orientations. The ORL dataset offers a realistic representation of face images encountered in real-world scenarios, making it a suitable choice for evaluating the performance of face recognition algorithms. The dataset has been extensively used for training and testing various dimensionality reduction techniques.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{The-ORL-database-for-training-and-testing.png}
    \caption{Our Database of Faces (ORL) Dataset}
    \label{fig:orl_faces}
\end{figure}

\subsection{COIL2000}
This dataset used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data. The data was supplied by the Dutch data mining company Sentient Machine Research and is based on a real world business problem. The training set contains over 5000 descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains 4000 customers of whom only the organizers know if they have a caravan insurance policy.

The dataset had class imbalance, as a large majority of customers have zero claims. Sklearn's \textit{RandomOverSampler} was used to balance it.
%\cite{van2004bias}

\subsection{FIFA}
The FIFA dataset encompasses data from various editions of the popular FIFA video game series, which serves as a reliable source of player information. The dataset contains detailed attributes for each player, including playing positions, skill ratings (such as dribbling, shooting, and passing), and performance statistics (such as goals, assists, and appearances).

Furthermore, it includes the estimated market value of each player, which has often been used as the dependent variable in a regression or classification task.

\section{Interpretation of Components}

The objective at hand is to determine the significance that each dimensionality reduction technique assigns to each of the original features. To accomplish this, we compute the ranking of the absolute correlation between the dimensions generated by the technique and the original features.

Before diving into the step-by-step process, it is essential to define some variables that are present in dimensionality reduction tasks: let the input data $X$ be an $n \times p$ matrix, where each row represents a sample and each column, denoted as $X_1, X_2, ..., X_p$, corresponds to a feature. Furthermore, let $V \in \mathbb{R}^{d \times p}$ be the projection matrix, i.e., the matrix that projects $p$-dimensional data into a $d$-dimensional subspace and let $V_i$ represent the $i$-th column of $V$ sorted in descending order by their significance (e.g., by the magnitude of their eigenvalues or the variability they capture). Finally let $P \in \mathbb{R}^{n \times d}$ be the the projection of the data into the $d$-dimensional space, so that $P = XV$ holds, with columns $P_1, P_2,..., P_d$.

The first step is to calculate the correlation between the input data represented in its original features $X_1, X_2, ..., X_p$ and the data projected onto the reduced $d$-dimensions $P_1, P_2, ..., P_d$. Let $r_i$ be the vector that contains the correlations between the input data $X$ and its projection onto the $i$-th dimension $P_i$.
$$
    r_i =
    \begin{bmatrix}
        corr(P_i, X_1) \\
        corr(P_i, X_2) \\
        ...            \\
        corr(P_i, X_p)
    \end{bmatrix}
$$

Correlation can be negative or positive. However, it is the absolute value what determines the degree of significance of the correlation. Therefore, we take the absolute values $|corr(P_i,X_j)|$. At the same time, the difference between the value of correlations is not uniform among the different dimensionality reduction techniques and it prevents us from doing a fair comparison. To address that, we take the position of the absolute correlation in a list that is sorted in ascending order. Let $index(j)$ be the index such that $\#\{i : x_i \leq x_j\} = \lfloor j \rfloor$ for $i, j \in \{1,2,...,p\}$.
$$
    s_i =
    \begin{bmatrix}
        index(|corr(P_i, X_1)|) \\
        index(|corr(P_i, X_2)|) \\
        ...                     \\
        index(|corr(P_i, X_p)|)
    \end{bmatrix}
$$

For example, suppose we have some input data with 3 features $X_1, X_2$ and $X_3$ and we would like to explain the first reduced dimension $P_1$. Suppose also the correlations $corr(P_1, X_1), corr(P_1, X_2)$ and $corr(P_1, X_3)$ are $-0.9, 0.3$ and $0.7$ respectively. Vector $r_1$ would written as
$$
    r_1 =
    \begin{bmatrix}
        -0.9 \\
        0.3  \\
        0.7
    \end{bmatrix},
$$
and vector $s_1$ as
$$
    s_1 =
    \begin{bmatrix}
        3 \\
        1 \\
        2
    \end{bmatrix}.
$$

% Now we have a vector that explains a dimension. The objective is to compare the dimensions by the importance that they give to each of the original features.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import Dim\n",
    "from datasets import fifa\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dim. red. framework\n",
    "dim = Dim()\n",
    "\n",
    "# Load dataset\n",
    "fif = fifa()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fif.X, fif.y, test_size=0.1, random_state=33)\n",
    "dim.col_names = fif.col_names\n",
    "dim.X_train = X_train\n",
    "dim.y_train = y_train\n",
    "dim.X_test = X_test\n",
    "dim.y_test = y_test\n",
    "\n",
    "dim.new_dim = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unplickle dim\n",
    "dim.unpickle_dim('dim/02-11-12:42.pkl')\n",
    "\n",
    "# Read scores\n",
    "scores = pd.read_csv('scores/07-04-20:42.csv')\n",
    "\n",
    "# Filter for the best configuration\n",
    "best_sc = scores.loc[scores.sort_values('Dimensions').groupby('Dim. Technique')['Accuracy'].idxmax()]\n",
    "\n",
    "# Transform rows to dictionary keys\n",
    "best_sc = [tuple(row) for row in best_sc[['Dimensions', 'Dim. Technique', 'Dim. Params']].to_records(index=False)]\n",
    "\n",
    "# List execution parameters to plot\n",
    "best_sc = [('3Dim', 'KPCA', 'Linear'),\n",
    " ('5Dim', 'LLE', 'k=81-reg=0.001'),\n",
    " ('5Dim', 'LOL', ''),\n",
    " ('4Dim', 'LPP', 'k=5'),\n",
    " ('3Dim', 'PCA', ''),\n",
    " ('2Dim', 'SLMVP', 'Radial-Gammas=0.1')]\n",
    "\n",
    "# Select only the executions with the parameters of 'best_sc'\n",
    "newdict = {k: dim.new_dim[k] for k in best_sc}\n",
    "dim.new_dim = newdict\n",
    "\n",
    "# Get the variability \n",
    "weights = dim.get_weights().droplevel(3, axis=1)\n",
    "\n",
    "# Format weights\n",
    "weigts_c = []\n",
    "for key in dim.new_dim.keys():\n",
    "    if weigts_c != '':\n",
    "        weigts_c = weigts_c + weights[key].tolist()\n",
    "weigts_c = [x for x in weigts_c if x != '']\n",
    "\n",
    "# Get the  correlations\n",
    "corrs = dim.get_corr_table(num_dim=None, abs=False)\n",
    "\n",
    "# Multiply each column by corresponding weigth\n",
    "for i, col in enumerate(corrs.columns):\n",
    "    corrs[col] *= weigts_c[i]\n",
    "\n",
    "# Initialize dictionary to hold lists of tuples\n",
    "result_dict = {}\n",
    "\n",
    "# Group tuples by their second element\n",
    "for tup in corrs.keys():\n",
    "\n",
    "    if tup[1] not in result_dict:\n",
    "        result_dict[tup[1]] = [(tup)]\n",
    "    else:\n",
    "        result_dict[tup[1]].append((tup))\n",
    "\n",
    "# Convert dictionary values to lists\n",
    "header_groups = [values for values in result_dict.values()]\n",
    "\n",
    "corrs_avg = pd.DataFrame()\n",
    "for header_g in header_groups:\n",
    "    corrs_avg[header_g[0][1]] = corrs[header_g].abs().mean(axis=1)\n",
    "\n",
    "corrs_avg.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs['skill_set'] = corrs.index.to_series().str.split(\"_\").str[0]\n",
    "colors = corrs['skill_set'].map(\n",
    "    {'attacking': '#1f77b4',\n",
    "     'skill': '#2ca02c',\n",
    "     'movement' : '#d62728',\n",
    "     'power' : '#9467bd',\n",
    "     'mentality' : '#ff7f0e',\n",
    "     'defending' : '#7f7f7f'})\n",
    "\n",
    "corrs.drop(columns=['skill_set'], inplace=True)\n",
    "\n",
    "n_rows = 6\n",
    "n_cols = 6\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    n_rows, n_cols, figsize=(22, 45), sharey='row')\n",
    "\n",
    "# Plot\n",
    "pos = -1\n",
    "for idx, key_dim in enumerate(list(corrs.keys())):\n",
    "    values = corrs[key_dim]#.sort_values(ascending=True)\n",
    "    categories = values.index\n",
    "    if key_dim[-1] == 0:\n",
    "        pos += 1\n",
    "    ax[pos][key_dim[-1]+1].barh(categories, values, color=colors)\n",
    "    #ax[floor(idx/n_cols)][idx % n_cols].set_title(key_dim)\n",
    "\n",
    "# Plot avgs\n",
    "for idx, key_dim in enumerate(list(corrs_avg.keys())):\n",
    "    values = corrs_avg[key_dim]#.sort_values(ascending=True)\n",
    "    categories = values.index\n",
    "    ax[idx][0].barh(categories, values, color=colors)\n",
    "    \n",
    "# Add column labels\n",
    "col_labels = ['Avg.', '1', '2', '3', '4', '5']\n",
    "for ax_, col in zip(ax[0], col_labels):\n",
    "    ax_.annotate(col, xy=(0.5, 1), xytext=(0, 20),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size=30, ha='center', va='baseline')\n",
    "\n",
    "# Add row lables\n",
    "row_labels = [x[1] + '\\n' + x[2] for x in corrs.keys().to_list()]\n",
    "row_labels = [x for i, x in enumerate(row_labels) if x not in row_labels[:i]]\n",
    "for ax_, row in zip(ax[:,0], row_labels):\n",
    "    ax_.annotate(row, xy=(0, 0.5), xytext=(-ax_.yaxis.labelpad - 75, 0),\n",
    "                xycoords=ax_.yaxis.label, textcoords='offset points',\n",
    "                size=20, ha='center', va='center')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.0)  # Adjusting spacing between subplots\n",
    "\n",
    "# Set the range of the x-axis for all plots\n",
    "for ax_row in ax:\n",
    "    # Get x-axis range for the correlations of the dim with the highest\n",
    "    xlims = [x.get_xlim() for x in ax_row[1:]]\n",
    "    # Remove x lims for the empty plots, tuples (0.0, 1.0)\n",
    "    xlims = [x for x in xlims if x != (0.0, 1.0)]\n",
    "    # Select the biggest xlim\n",
    "    xlim = max(xlims, key=lambda t: abs(t[0] - t[1]))\n",
    "    for ax_ in ax_row[1:]:\n",
    "        ax_.set_xlim(xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection #10\n",
    "\n",
    "1. Calculates the weighted average of the components-features absolute correlations (previously calculated)\n",
    "2. Orders the features by those average correlations in descending order\n",
    "3. Trains ML classifiers that use the top 1, top 2, ..., top n features using AUROC as the performance metric\n",
    "4. Creates plots like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the calculated weighted average of the components-features absolute correlations\n",
    "# Order the features by those average correlations in descending order\n",
    "features = {}\n",
    "for dim_t in corrs_avg.keys():\n",
    "    features[dim_t] = corrs_avg[[dim_t]].sort_values(by=dim_t, ascending=False).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 9]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = ['attacking_crossing',\n",
    " 'skill_ball_control']\n",
    "indices = [fif.col_names.index(attr) for attr in feats]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 28, 62, ..., 60, 60, 60],\n",
       "       [36, 59, 57, ..., 22, 25, 23],\n",
       "       [37, 25, 75, ..., 81, 77, 68],\n",
       "       ...,\n",
       "       [41, 33, 59, ..., 52, 62, 67],\n",
       "       [31, 27, 71, ..., 68, 71, 64],\n",
       "       [35, 22, 52, ..., 51, 50, 49]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 29)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,[0,9]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attacking_crossing',\n",
       " 'attacking_finishing',\n",
       " 'attacking_heading_accuracy',\n",
       " 'attacking_short_passing',\n",
       " 'attacking_volleys',\n",
       " 'skill_dribbling',\n",
       " 'skill_curve',\n",
       " 'skill_fk_accuracy',\n",
       " 'skill_long_passing',\n",
       " 'skill_ball_control',\n",
       " 'movement_acceleration',\n",
       " 'movement_sprint_speed',\n",
       " 'movement_agility',\n",
       " 'movement_reactions',\n",
       " 'movement_balance',\n",
       " 'power_shot_power',\n",
       " 'power_jumping',\n",
       " 'power_stamina',\n",
       " 'power_strength',\n",
       " 'power_long_shots',\n",
       " 'mentality_aggression',\n",
       " 'mentality_interceptions',\n",
       " 'mentality_positioning',\n",
       " 'mentality_vision',\n",
       " 'mentality_penalties',\n",
       " 'mentality_composure',\n",
       " 'defending_marking_awareness',\n",
       " 'defending_standing_tackle',\n",
       " 'defending_sliding_tackle',\n",
       " 'position']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fif.col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,[0,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 27, 21]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "indices = [fif.col_names.index(x) for x in features['KPCA'][:3]]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (25,108) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  3%|▎         | 1/29 [03:33<1:39:33, 213.36s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 28 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-125e229c1c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Select feature subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 28 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# Instantiate dim. red. framework\n",
    "dim = Dim()\n",
    "\n",
    "# Load dataset\n",
    "fif = fifa()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fif.X, fif.y, test_size=0.1, random_state=33)\n",
    "dim.col_names = fif.col_names\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'Features': [''],\n",
    "    'SVM_Accuracy': [0],\n",
    "    'XGBoost_Accuracy': [0]\n",
    "}\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "for dim_t in features:\n",
    "    for i in tqdm(range(1, 30)):\n",
    "\n",
    "        if frozenset(features[dim_t][:i]) not in results_df['Features'].values:\n",
    "            # Select feature subset\n",
    "            indices = [fif.col_names.index(x) for x in features[dim_t][:i]]\n",
    "            X_train_subset = X_train[:, indices]\n",
    "            X_test_subset = X_test[:, indices]\n",
    "\n",
    "            # Train ML classifier\n",
    "            # SVM\n",
    "            svm_pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                                 ('svm', SVC())])\n",
    "            params = [{'svm__C': [0.1, 1, 10],\n",
    "                       'svm__kernel': ['linear', 'rbf', 'poly']}]\n",
    "            gs_svm = GridSearchCV(svm_pipe,\n",
    "                                  param_grid=params,\n",
    "                                  scoring='accuracy',\n",
    "                                  cv=5)\n",
    "            gs_svm.fit(X_train_subset, y_train)\n",
    "            # Calculate AUROC and other performance metrics\n",
    "            svm_accuracy = accuracy_score(y_test, gs_svm.predict(X_test_subset))\n",
    "\n",
    "            # XGBOOST            \n",
    "            xgb_pipe = Pipeline([('mms', MinMaxScaler()), ('xgb', XGBClassifier())])\n",
    "            params = [{'xgb__n_estimators': [5, 10, 20, 50, 100]}]\n",
    "            gs_xgb = GridSearchCV(xgb_pipe,\n",
    "                                  param_grid=params,\n",
    "                                  scoring='accuracy',\n",
    "                                  cv=5)\n",
    "            gs_xgb.fit(X_train_subset, y_train)\n",
    "            # Calculate AUROC and other performance metrics\n",
    "            xgb_accuracy = accuracy_score(y_test, gs_xgb.predict(X_test_subset))\n",
    "            # Save results\n",
    "            results_df = results_df.append({'Features': frozenset(features[dim_t][:i]),\n",
    "                                            'SVM_Accuracy': svm_accuracy,\n",
    "                                            'XGBoost_Accuracy': xgb_accuracy}, ignore_index=True)\n",
    "\n",
    "    # Export DataFrame to CSV\n",
    "    results_df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
